import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
plt.rcParams.update({'figure.max_open_warning': 0})
from matplotlib.backends.backend_pdf import PdfPages

def load_dat(path): #given an excel file at the location 'path', loads it and converts it to useable python object
    apd = pd.read_excel(path) #opens file in pandas file format
    anu = apd.to_numpy() #converts to numpy array
    
    col_names = list(apd.columns)
    return anu,col_names #returns the data (anu), and the titles of every column of the array, which corresponds to a question

def dept2dist(dept): #given a department, returns which district it's in. Uses excel files I made with lists of department names
    tandon = sum(pd.read_excel("tandon.xlsx").to_numpy()==dept)
    stem = sum(pd.read_excel("stem.xlsx").to_numpy()==dept)
    ssh = sum(pd.read_excel("ssh.xlsx").to_numpy()==dept)
    stein = sum(pd.read_excel("steinhardt.xlsx").to_numpy()==dept)
    prof = sum(pd.read_excel("profschools.xlsx").to_numpy()==dept)
    
    if tandon:
        return "Tandon"
    elif stem:
        return "STEM"
    elif ssh:
        return "SSH"
    elif stein:
        return "Steinhardt"
    elif prof:
        return "Prof. Schools"
    else:
        return "Other"

def demo_info(data): #pulls all the demographic info, takes in the data array generated by load_dat()
    demo_data = data[:,0:22]

    n_nums = demo_data[:,1]
    emails = demo_data[:,2]
    n_years = demo_data[:,3]
    prog = demo_data[:,4]
    dept = demo_data[:,5]
    
    ifnot_dept = demo_data[:,6]
    dept[dept=="***Not Listed***"] = ifnot_dept[dept=="***Not Listed***"]

    dept_emp = demo_data[:,7]
    ifnot_dept_emp = demo_data[:,8]
    dept_emp[dept_emp=="***Not Listed***"] = ifnot_dept_emp[dept_emp=="***Not Listed***"]

    job = demo_data[:,9]
    if_int = demo_data[:,10]
    if_dif = demo_data[:,11]
    age = demo_data[:,12]
    race = demo_data[:,13]
    gend = demo_data[:,14]
    if_trans = demo_data[:,15]
    sex_orient = demo_data[:,16]
    if_notsingle = demo_data[:,17]
    immig = demo_data[:,18]
    dep = demo_data[:,19]
    paysource = demo_data[:,20]
    commute = demo_data[:,21]

    return gend,dept,if_int,prog #these are some demographic information pieces we want to use. Can ask to pull others if need be

def getpage(n): #returns relevant columns for a given page (first,last inclusive)
    if n==3:
        return 22,29
    elif n==4:
        return 30,36
    elif n==5:
        return 37,42
    elif n==6:
        return 43,53
    elif n==7:
        return 54,61
    elif n==8:
        return 62,69
    elif n==9:
        return 70,77
    elif n==10:
        return 78,105
    elif n==11:
        return 106,112
    elif n==12:
        return 113,120
    else:
        print("page number requested is either not present in data, or isn't one of the ones we're supposed to be analyzing >:( \n")

def convert_to_nums(column): #for a column with "not important ... gotta have it" answers, converts them to 1-5
    n = len(column)
    out = np.zeros(n)
    for i in range(n):
        if column[i] == "Not important":
            out[i] = 1
        elif column[i] == "Not too important":
            out[i] = 2
        elif column[i] == "Important":
            out[i] = 3
        elif column[i] == "Very important":
            out[i] = 4
        elif column[i] == "Gotta have it":
            out[i] = 5
        else:
            out[i] = float("nan")
    return out #returns the column with numerical components instead of strings

def pageres(page,data): #converts a whole page of the survey to numbers, column by column
    npeeps = len(data[:,1])
    start,stop = getpage(page)
    cols = range(start,stop+1)
    res = np.zeros((npeeps,len(cols)))
    for i in range(len(cols)):
        res[:,i] = convert_to_nums(data[:,cols[i]])
        
    return res 

def most_important(pagenum,pageres): #given a page of data, returns which question on the page is the most important to people
    tot_resp = sum(res,0) #adds up all the responses for each column
    maxloc = where(tot_resp==max(tot_resp)) #finds column with highest total response
    start,stop = getpage(pagenum)
    maxloc_fin = start+maxloc

    return maxloc_fin #this number can be used to get the question by calling col_names[maxloc_fin], where col_names is the second output of the load_dat() function

def most_divisive(pagenum,pageres): #same thing as above, but returns the question with the highest standard deviation. I think there can be improvements in this metric...
    std_resp = std(res,0) #standard deviation of the responses for each column
    maxloc = where(tot_resp==max(tot_resp)) #finds column with highest total response
    start,stop = getpage(pagenum)
    maxloc_fin = start+maxloc

    return maxloc_fin

def analyze_page_generic(pagenum,path,titlestr): #performs full analysis on one page of questions. Takes in the page number, the path to the data file, and the title of the output file. saves the data as a pdf in that location. 
    all_data,all_col_names = load_dat(path)
    gend,dept,ifint,prog = demo_info(all_data)
    results = pageres(pagenum,all_data)
    
    start,stop = getpage(pagenum)
    col_names = all_col_names[start:(stop+1)]
    ncol = len(range(start,stop+1))
    pp = PdfPages(titlestr)
    plt.text(.5,.5,"Page "+str(pagenum),
          bbox={'facecolor':'white','alpha':1,'edgecolor':'none','pad':1},
          ha='center', va='center',wrap=True)
    plt.axis('off')
    for i in range(ncol):
        fig = plt.figure()
        colres = results[:,i]
        if not np.isnan(sum(colres)):
            yvals = [sum(colres==i) for i in range(1,6)]
            plt.bar([1,2,3,4,5],yvals,tick_label = np.array(["Not imp.","Not too imp.","Imp.","Very imp.","Gotta"])) #bar plots for each question
            plt.title(col_names[i],fontsize=7,wrap=True)
            pp.savefig(fig)
        
    tot_resp = sum(results,0)
    std_resp = np.std(results,0)
    keep = (np.logical_not(np.isnan(tot_resp)))

    fig = plt.figure()
    plt.plot(range(1,sum(keep)+1),tot_resp[keep],".") #plots total interest for all the questions
    plt.xticks(list(range(1,sum(keep)+1)))
    plt.title('Total interest per question on page')
    pp.savefig(fig)
    
    fig = plt.figure()
    plt.plot(range(1,sum(keep)+1),std_resp[keep],".") #same thing as above, with standard deviation
    plt.xticks(list(range(1,sum(keep)+1)))
    plt.title('Divisiveness of questions on page')
    pp.savefig(fig)
    plt.close('all')

    pp.close()    

def group_depts(depts):
    out = depts.copy()

    for i in range(len(depts)):
        out[i] = dept2dist(depts[i]) #converts departments to districts, by calling the dept2dist() function from above

    return out

def analyze_question_generic(pagenum,qnum,titlestr,path): #Once a specific question is identified as divisive, this performs some demographic analysis on it. Takes page number, question number on that page, name of the save location, and the path to the data file
    all_data,all_col_names = load_dat(path)
    gend,dept,ifint,prog = demo_info(all_data) #If you want to use other demographic info, just pull different arrays in the demo_info() function above!
    distr = group_depts(dept)
    results = pageres(pagenum,all_data)
    
    start,stop = getpage(pagenum)
    col_names = all_col_names[start:(stop+1)]
    ncol = len(range(start,stop+1))
    pp = PdfPages(titlestr)
 
    this_col = results[:,qnum-1]
    name = col_names[qnum-1]
    
    fig = plt.figure()
    plt.text(.5,.5,name,
          bbox={'facecolor':'white','alpha':1,'edgecolor':'none','pad':1},
          ha='center', va='center',wrap=True)
    plt.axis('off')
    pp.savefig(fig)

    fig = plt.figure() #gender breakdown. For now... binary
    m = this_col[(gend=="Man")]
    f = this_col[(gend=="Woman")]
    o = this_col[np.array(np.ones(gend.shape)-(gend=="Man")-(gend=="Woman"),dtype=bool)]
    plt.boxplot([m,f,o],labels=["Man","Woman","Non-binary"])
    plt.title("Importance by gender (coarse)")
    pp.savefig(fig)

    fig = plt.figure() #district breakdown
    ssh = this_col[(distr=="SSH")]
    stem = this_col[(distr=="STEM")]
    stein = this_col[(distr=="Steinhardt")]
    tandon = this_col[(distr=="Tandon")]
    prof = this_col[(distr=="Prof. Schools")]
    other = this_col[(distr=="Other")]
    plt.boxplot([ssh,stem,stein,tandon,prof,other],labels=["SSH","STEM","Steinhardt","Tandon","Prof. Schools","Other"])
    plt.title("Importance by district")
    pp.savefig(fig)

    fig = plt.figure() #breakdown by international student or not
    plt.boxplot([this_col[ifint=="Yes"],this_col[ifint=="No"]],labels=["International","Domestic"])
    plt.title("Importance by nationality")
    pp.savefig(fig)

    fig = plt.figure() #breakdown by program
    plt.boxplot([this_col[prog=="PhD"],this_col[prog=="Master's"]],labels=["PhD","Masters"])
    plt.title("Importance by program type")
    pp.savefig(fig)
    plt.close('all')

    #You can add more code like the above sections, to generate plots of more demographic breakdowns, just make sure to pull the data using demo_info()
    pp.close()


def scripty(path): #just a script for me
    print("Pagewise analysis...\n")
    #Analyze all non optional pages and put output in the results folder
    pages = [3,4,5,6,8,10,11]
    for p in pages:
        analyze_page_generic(p,path,"results/page"+str(p)+".pdf")
    
    print("Question analysis...\n")
    #Change this as you desire: specific questions to be analyzed
    pages = [3,3,4,4]
    questions = [2,6,1,3]
    for i in range(len(pages)):
        analyze_question_generic(pages[i],questions[i],"results/p"+str(pages[i])+"q"+str(questions[i])+".pdf",path)

    print("Done!\n")
